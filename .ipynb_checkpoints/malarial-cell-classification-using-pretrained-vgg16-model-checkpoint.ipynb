{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "flying-margin",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "basic-marina",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1afd6482db64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.optimizers as Optimizer\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Set the `numpy` pseudo-random generator at a fixed value\n",
    "#This helps with repeatable results everytime you run the code. \n",
    "np.random.seed(1000)\n",
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-hardware",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through all images in Parasitized folder, resize to 224 x 224\n",
    "#and save the resized image as numpy array to 'dataset' variable, and set the label of parasitized cells to '0'\n",
    "\n",
    "image_directory = 'images/'\n",
    "SIZE = 224\n",
    "dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  \n",
    "label = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.\n",
    "\n",
    "parasitized_images = os.listdir(image_directory + 'Parasitized/')\n",
    "for i, image_name in enumerate(parasitized_images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv.imread(image_directory + 'Parasitized/' + image_name)\n",
    "        image = cv.resize(image,(SIZE,SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "\n",
    "#Iterate through all images in Uninfected folder, resize to 224 x 224\n",
    "#and save the resized image as numpy array to 'dataset' variable, and set the label of parasitized cells to '1'\n",
    "\n",
    "uninfected_images = os.listdir(image_directory + 'Uninfected/')\n",
    "for i, image_name in enumerate(uninfected_images):\n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv.imread(image_directory + 'Uninfected/' + image_name)\n",
    "        image = cv.resize(image,(SIZE,SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-california",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_pretrain_cnn_model(img_size):\n",
    "    # img_size = 224\n",
    "    # https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
    "    # VGG-16 Architecture\n",
    "    base_model = VGG16(input_shape = (img_size, img_size, 3), # Shape of our images\n",
    "    include_top = False, # Leave out the last fully connected layer\n",
    "    weights = 'imagenet')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Flatten the output layer to 1 dimension\n",
    "    x = layers.Flatten()(base_model.output)\n",
    "\n",
    "    # Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "    # Add a dropout rate of 0.5\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Add a final sigmoid layer with 1 node for classification output\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(base_model.input, x)\n",
    "    model.compile(optimizer = Optimizer.Adam(learning_rate=0.0001), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-johns",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(test_y, predictions):\n",
    "    accuracy = sklearn.metrics.accuracy_score(test_y, predictions)\n",
    "    precision = sklearn.metrics.precision_score(test_y, predictions)\n",
    "    recall = sklearn.metrics.recall_score(test_y, predictions)\n",
    "    f1 = sklearn.metrics.f1_score(test_y, predictions)\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_roc_and_pr_curve(test_y, probas,a,p,r,f1):\n",
    "    fpr,tpr,thr = roc_curve(test_y, probas)\n",
    "    precision, recall, thresholds = precision_recall_curve(test_y, probas)\n",
    "\n",
    "    roc_fig = px.area(\n",
    "        x=fpr, y=tpr,\n",
    "        title=f'ROC Curve (AUC={auc(fpr, tpr):.4f}), Accuracy={a:.2f}',\n",
    "        labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    roc_fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1\n",
    "    )\n",
    "\n",
    "    roc_fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    roc_fig.update_xaxes(constrain='domain')\n",
    "    roc_fig.show()\n",
    "    \n",
    "    pr_fig = px.area(\n",
    "        x=recall, y=precision,\n",
    "        title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f}), Precision={p:.2f}, Recall={r:.2f}, F1={f1:.2f}',\n",
    "        labels=dict(x='Recall', y='Precision'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    pr_fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=1, y1=0\n",
    "    )\n",
    "    pr_fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    pr_fig.update_xaxes(constrain='domain')\n",
    "    pr_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset \n",
    "# Split the dataset into training and testing dataset.\n",
    "# 1. Training data: 80%\n",
    "# 2. Testing data: 20%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)\n",
    "\n",
    "model = vgg16_pretrain_cnn_model(SIZE)\n",
    "\n",
    "y_train = np.asarray(y_train).astype('int32').reshape((-1,1))\n",
    "y_test = np.asarray(y_test).astype('int32').reshape((-1,1))\n",
    "\n",
    "model.fit(np.array(X_train), y_train, batch_size = 32, epochs = 15, validation_split = 0.1, shuffle = False)\n",
    "\n",
    "    \n",
    "preds = model.predict(X_test)\n",
    "flatten_preds_probas = preds.flatten()\n",
    "actual_preds = (flatten_preds_probas > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy, precision, recall, f1_score = metrics(y_test,actual_preds)\n",
    "print(\"Accuracy: \", accuracy, \"Precision: \", precision, \"Recall: \", recall, \"F1_score: \", f1_score)\n",
    "show_roc_and_pr_curve(y_test, flatten_preds_probas,accuracy,precision,recall,f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
